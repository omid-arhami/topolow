---
title: "Parameter Fitting with Synthetic Datasets - All Variants"
author: "Omid Arhami"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parameter Fitting with Synthetic Datasets - All Variants}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 6,
  warning = TRUE,
 message = TRUE,    # Show messages
  error = TRUE      # Continue on error
)
```

## Introduction

This vignette demonstrates parameter fitting for synthetic datasets across different:
* Dimensionalities (2D, 5D, 10D)
* Missing data patterns (S, M, L levels)
* Noise types (random noise & biased noise)

Here we create 80 points for a faster analysis, but in the paper results with 250 points are shown.

## Required Packages

```{r}
library(topolow)
library(ggplot2)
library(dplyr)
#library(data.table)
library(gridExtra)
```

## Generate Synthetic Datasets

First, let's create synthetic datasets with different dimensionalities:

```{r}
# Generate datasets in 2, 5, and 10 dimensions
results <- generate_synthetic_datasets(
  n_dims_list = c(2, 5, 10),
  seeds = c(123450, 903450, 13450),
  n_points = 250,
  output_dir = "synthetic_data"
)

# Print dataset properties
print(results$metadata)

# List available matrix variants for each dimension
matrix_variants <- names(results$matrices[[1]])[c(3,4,6,7,8,10,11,12,14)]
print("Available matrix variants:")
print(matrix_variants)
```

## Parameter Optimization Setup

Define consistent parameter ranges and optimization settings:

```{r}
# Define parameter ranges
param_ranges <- list(
  N_min = 2,          # Minimum dimensions 
  N_max = 30,         # Maximum dimensions
  k0_min = 0.5,         # Minimum spring constant
  k0_max = 30,        # Maximum spring constant 
  cooling_rate_min = 1e-4, # Minimum decay rate
  cooling_rate_max = 0.05, # Maximum decay rate
  c_repulsion_min = 1e-4,    # Minimum repulsion constant
  c_repulsion_max = 0.05     # Maximum repulsion constant
)

# Setup optimization parameters
opt_params <- list(
  mapping_max_iter = 1000,    # Maximum map optimization iterations
  folds = 20,         # Number of CV folds
  num_samples = 40,
  use_slurm = TRUE,
  cider = TRUE,
  write_files = TRUE  # Only set TRUE on SLURM
)
```

## Initial Parameter Search

We'll run some optimization trials for each dimension and matrix variant to build an initial estimate of likelihood in the parameter space:

```{r eval=FALSE}
# Run optimization for each dimensionality and matrix variant
for(i in seq_along(results$matrices)) { 
  dim_data <- results$matrices[[i]]
  ndim <- results$metadata$dimension[i]
  
  for(matrix_type in matrix_variants) { 
    # Get current matrix
    distance_matrix <- dim_data[[matrix_type]]
    
    # Create scenario name incorporating dimension and matrix type
    scenario_name <- sprintf("synthetic_AMC103_dim%d_%s", ndim, matrix_type)
    
    message(sprintf("\nOptimizing for %d dimensions, matrix type: %s", 
                   ndim, matrix_type))
    
    # Run optimization
    opt_result <- initial_parameter_optimization(
      distance_matrix = distance_matrix,
      mapping_max_iter = opt_params$mapping_max_iter,
      relative_epsilon = 1e-4,
      convergence_counter = 5,
      scenario_name = scenario_name,
      N_min = param_ranges$N_min, 
      N_max = param_ranges$N_max,
      k0_min = param_ranges$k0_min,
      k0_max = param_ranges$k0_max, 
      c_repulsion_min = param_ranges$c_repulsion_min,
      c_repulsion_max = param_ranges$c_repulsion_max,
      cooling_rate_min = param_ranges$cooling_rate_min,
      cooling_rate_max = param_ranges$cooling_rate_max,
      folds = opt_params$folds,
      num_samples = opt_params$num_samples,
      write_files = opt_params$write_files,
      time = "4:00:00",
      memory = "1G",
      use_slurm = opt_params$use_slurm,
      cider = opt_params$cider,
      verbose = TRUE
    )
  }
}
```

## Aggregate Results 

After SLURM jobs complete, aggregate results for each dimension and matrix type:

```{r eval=FALSE}
# Initialize results storage
all_results <- list()

# Aggregate results for each dimension and matrix type
for(ndim in results$metadata$dimension) { 
  dim_results <- list()
  
  for(matrix_type in matrix_variants) { #
    scenario_name <- sprintf("synthetic_AMC103_dim%d_%s", ndim, matrix_type)
    print(scenario_name)
    # Aggregate optimization results
    dim_results[[matrix_type]] <- aggregate_parameter_optimization_results(
      scenario_name = scenario_name,
      write_files = TRUE
    )
  }
  
  all_results[[as.character(ndim)]] <- dim_results
}
```

## Adaptive Monte Carlo Sampling

Perform adaptive sampling for each case:

```{r eval=FALSE}
# Setup adaptive sampling parameters
amc_params <- list(
  num_parallel_jobs = 1500,  # For local execution: Number of CPU cores available; For SLURM: Number of samples
  num_samples = 1500,        # Number of new samples to be added to the parameter distribution through AMC (for refinement.) If using SLURM, can set = num_parallel_jobs for better accounting.
  mapping_max_iter = 1000,    # Maximum iterations per map optimization
  relative_epsilon = 1e-4
)

# Setup optimization parameters
opt_params <- list(
  folds = 20,         # Number of CV folds
  use_slurm = TRUE,
  cider = TRUE
)

# Run adaptive sampling for each dimension and matrix type
for(ndim in results$metadata$dimension) { 
  dim_data <- results$matrices[[which(results$metadata$dimension == ndim)]]
  
  for(matrix_type in matrix_variants) { # 
    # Get scenario names
    base_scenario <- sprintf("synthetic_AMC105_dim%d_%s", ndim, matrix_type)
    amc_scenario <- base_scenario #sprintf("%s_amc", base_scenario)
    
    # Get result file path
    result_file <- file.path("model_parameters", 
                            sprintf("%s_model_parameters.csv", base_scenario))
    log_transform_parameters(result_file)
    
    # Get corresponding distance matrix
    distance_matrix <- dim_data[[matrix_type]]
    
    message(sprintf("\nRunning adaptive sampling for %d dimensions, matrix type: %s", 
                   ndim, matrix_type))
    
    # Run adaptive sampling for current scenario (K-fold cross-validation happens inside) 
    run_adaptive_sampling(
      initial_samples_file = result_file,
      distance_matrix = distance_matrix,
      mapping_max_iter = amc_params$mapping_max_iter,
      scenario_name = amc_scenario,
      num_parallel_jobs = amc_params$num_parallel_jobs,
      num_samples = amc_params$num_samples,
      max_cores = 21, # Each job on SLURM can work with 20 cores for a 20-fold CV
      relative_epsilon = amc_params$relative_epsilon,
      folds = opt_params$folds,
      time = "3:00:00",
      memory = "1G",
      use_slurm = opt_params$use_slurm,
      cider = opt_params$cider,
      verbose = TRUE
    )
  }
}
```

## Analyze fitted parameters Across Dimensions and Matrix Types

After all jobs complete, analyze parameter variations:

```{r}
# Initialize results collection
final_params <- data.frame()
# Collect results for each dimension and matrix type
for(ndim in results$metadata$dimension) {
  for(matrix_type in matrix_variants) {
    # Read AMC results
    amc_files <- c(
                   file.path("model_parameters",
                         sprintf("synthetic_AMC102_dim%d_%s_model_parameters.csv", 
                                ndim, matrix_type))
                   )
    # Combine chain results
    amc_results <- do.call(rbind, lapply(amc_files, read.csv))
    
    # Ensure numeric columns are properly converted
    numeric_columns <- c("log_N", "log_k0", "log_cooling_rate", "log_c_repulsion", "NLL", "Holdout_MAE")
    for(col in numeric_columns) {
      if(col %in% names(amc_results)) {
        amc_results[[col]] <- as.numeric(as.character(amc_results[[col]]))
      }
    }
    
    amc_results <- amc_results %>%
      filter(is.finite(NLL) & is.finite(Holdout_MAE)) %>%
      na.omit()
    amc_results <- amc_results[amc_results$log_N >= log(2),]
    
    # Only clean numeric columns
    numeric_cols <- sapply(amc_results, is.numeric)
    amc_results[numeric_cols] <- lapply(amc_results[numeric_cols], clean_data, k = 4)
    amc_results <- na.omit(amc_results)
    
    # Find best parameters (minimum NLL)
    if(nrow(amc_results) > 0) {
      best_params <- amc_results[which.min(amc_results$Holdout_MAE),]
      best_params$true_dim <- ndim
      best_params$matrix_type <- matrix_type
      best_params$N <- round(exp(best_params$log_N))
      
      final_params <- rbind(final_params, best_params)
    } else {
      cat("Warning: No valid results for dimension", ndim, "and matrix type", matrix_type, "\n")
    }
  }
}

write.csv(final_params, "optimal_parameters_250points_AMC102.csv")
```


## Convergence Analysis

Check convergence for each case:

```{r}
# A helper function:
analyze_convergence <- function(ndim, matrix_type, mutual_size) {
  # Create the two specific file patterns we want to match
  file_patterns <- c(
    sprintf("synthetic_AMC101_dim%d_%s_model_parameters.csv", ndim, matrix_type),
    sprintf("synthetic_AMC102_dim%d_%s_model_parameters.csv", ndim, matrix_type)
  )

  # Get full paths for both files
  chain_files <- file.path("model_parameters", file_patterns)

  # Verify files exist
  if (!all(file.exists(chain_files))) {
    missing_files <- chain_files[!file.exists(chain_files)]
    warning("Missing chain files: ", paste(missing_files, collapse = ", "))
    chain_files <- chain_files[file.exists(chain_files)]
    if (length(chain_files) == 0) {
      stop("No chain files found for dimension ", ndim, " and matrix type ", matrix_type)
    }
  }

  # Calculate diagnostics
  diag <- calculate_diagnostics(chain_files, mutual_size = mutual_size)

  # Create diagnostic plots
  plot_file <- sprintf("synthetic_dim%d_%s_diagnostics.png", ndim, matrix_type)
  p <- create_diagnostic_plots(chain_files, mutual_size = mutual_size,
                             output_file = plot_file)

  return(list(diagnostics = diag, plot = p))
}

# Set the mutual_size, smaller then the minimum simulaations for each scenario:
mutual_size <- 100

# Analyze convergence for each case
convergence_results <- list()
for(ndim in results$metadata$dimension) {
  dim_results <- list()
  for(matrix_type in matrix_variants) {
    dim_results[[matrix_type]] <- analyze_convergence(ndim, matrix_type, mutual_size=mutual_size)
  }
}

# Print summary of convergence results
for(ndim in names(convergence_results)) {
  cat(sprintf("\nConvergence Summary for %s dimensions:\n", ndim))
  for(matrix_type in names(convergence_results[[ndim]])) {
    cat(sprintf("\nMatrix type: %s\n", matrix_type))
    print(convergence_results[[ndim]][[matrix_type]]$diagnostics)
  }
}
```


## Session Info

```{r}
sessionInfo()
```
