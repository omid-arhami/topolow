---
title: "Parameter Fitting with Synthetic Datasets - All Variants"
author: "Omid Arhami"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parameter Fitting with Synthetic Datasets - All Variants}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 6,
  warning = TRUE,
 message = TRUE,    # Show messages
  error = TRUE      # Continue on error
)
```

## Introduction

This vignette demonstrates parameter fitting for synthetic datasets across different:
* Dimensionalities (2D, 5D, 10D)
* Missing data patterns (S, M, L levels)
* Noise types (random noise & biased noise)

Here we create 80 points for a faster analysis, but in the paper results with 250 points are shown.

## Required Packages

```{r}
library(topolow)
library(ggplot2)
library(dplyr)
#library(data.table)
library(gridExtra)
```

## Generate Synthetic Datasets

First, let's create synthetic datasets with different dimensionalities:

```{r}
# Generate datasets in 2, 5, and 10 dimensions
results <- generate_synthetic_datasets(
  n_dims_list = c(2, 5, 10),
  seeds = c(123450, 903450, 13450),
  n_points = 250,
  output_dir = "synthetic_data"
)

# Print dataset properties
print(results$metadata)

# List available matrix variants for each dimension
matrix_variants <- names(results$matrices[[1]])[c(3,4,6,7,8,10,11,12,14)]
print("Available matrix variants:")
print(matrix_variants)
```

## Parameter Optimization Setup

Define consistent parameter ranges and optimization settings:

```{r}
# Define parameter ranges
param_ranges <- list(
  N_min = 2,          # Minimum dimensions 
  N_max = 30,         # Maximum dimensions
  k0_min = 0.5,         # Minimum spring constant
  k0_max = 30,        # Maximum spring constant 
  cooling_rate_min = 1e-4, # Minimum decay rate
  cooling_rate_max = 0.05, # Maximum decay rate
  c_repulsion_min = 1e-4,    # Minimum repulsion constant
  c_repulsion_max = 0.05     # Maximum repulsion constant
)

# Setup optimization parameters
opt_params <- list(
  max_iter = 1000,    # Maximum optimization iterations
  num_samples = 40,   # Number of LHS samples
  folds = 20,         # Number of CV folds
  num_cores = 1,     # Number of cores to use. If using SLURM: 1 core per LHS sampling job. Can try parallel::detectCores() on local machines
  use_slurm = TRUE
)
```

## Initial Parameter Search

We'll run some optimization trials for each dimension and matrix variant to build an initial estimate of likelihood in the parameter space:

```{r eval=FALSE}
# Run optimization for each dimensionality and matrix variant
for(i in seq_along(results$matrices)) { 
  dim_data <- results$matrices[[i]]
  ndim <- results$metadata$dimension[i]
  
  for(matrix_type in matrix_variants) { 
    # Get current matrix
    distance_matrix <- dim_data[[matrix_type]]
    
    # Create scenario name incorporating dimension and matrix type
    scenario_name <- sprintf("synthetic_AMC101_dim%d_%s", ndim, matrix_type)
    
    message(sprintf("\nOptimizing for %d dimensions, matrix type: %s", 
                   ndim, matrix_type))
    
    # Run optimization
    opt_result <- run_parameter_optimization(
      distance_matrix = distance_matrix,
      max_iter = opt_params$max_iter,
      relative_epsilon = 1e-4,
      convergence_counter = 5,
      scenario_name = scenario_name,
      N_min = param_ranges$N_min, 
      N_max = param_ranges$N_max,
      k0_min = param_ranges$k0_min,
      k0_max = param_ranges$k0_max, 
      c_repulsion_min = param_ranges$c_repulsion_min,
      c_repulsion_max = param_ranges$c_repulsion_max,
      cooling_rate_min = param_ranges$cooling_rate_min,
      cooling_rate_max = param_ranges$cooling_rate_max,
      num_samples = opt_params$num_samples,
      folds = opt_params$folds,
      num_cores = opt_params$num_cores,
      time = "8:00:00",
      memory = "2G",
      write_files = TRUE,
      use_slurm = opt_params$use_slurm,
      cider = TRUE,
      verbose = TRUE
    )
  }
}
```

## Aggregate Results 

After SLURM jobs complete, aggregate results for each dimension and matrix type:

```{r eval=FALSE}
# Initialize results storage
all_results <- list()

# Aggregate results for each dimension and matrix type
for(ndim in results$metadata$dimension) { 
  dim_results <- list()
  
  for(matrix_type in matrix_variants) { #
    scenario_name <- sprintf("synthetic_AMC101_dim%d_%s", ndim, matrix_type)
    print(scenario_name)
    # Aggregate optimization results
    dim_results[[matrix_type]] <- aggregate_parameter_optimization_results(
      scenario_name = scenario_name,
      write_files = TRUE
    )
  }
  
  all_results[[as.character(ndim)]] <- dim_results
}
```

## Adaptive Monte Carlo Sampling

Perform adaptive sampling for each case:

```{r eval=FALSE}
# Setup adaptive sampling parameters
amc_params <- list(
  num_samples = 600,  # Total samples to collect
  n_iter = 3,          # Number of consecutive iterations per job
  batch_size = 2,      # Samples per iteration
  max_iter = 1000,     # Maximum optimization iterations
  relative_epsilon = 1e-4
)

# Setup optimization parameters
opt_params <- list(
  max_iter = 1000,    # Maximum optimization iterations
  num_samples = 40,   # Number of LHS samples
  folds = 20,         # Number of CV folds
  num_cores = 20,     # Number of cores to use. Can try parallel::detectCores() on local machines. It would be best if num_cores is a multiple of batch_size*folds
  use_slurm = TRUE
)

# Run adaptive sampling for each dimension and matrix type
for(ndim in results$metadata$dimension) { 
  dim_data <- results$matrices[[which(results$metadata$dimension == ndim)]]
  
  for(matrix_type in matrix_variants) { # 
    # Get scenario names
    base_scenario <- sprintf("synthetic_AMC101_dim%d_%s", ndim, matrix_type)
    amc_scenario <- base_scenario #sprintf("%s_amc", base_scenario)
    
    # Get result file path
    result_file <- file.path("model_parameters", 
                            sprintf("%s_model_parameters.csv", base_scenario))
    log_transform_parameters(result_file)
    
    # Get corresponding distance matrix
    distance_matrix <- dim_data[[matrix_type]]
    
    message(sprintf("\nRunning adaptive sampling for %d dimensions, matrix type: %s", 
                   ndim, matrix_type))
    
    # Run adaptive sampling for current scenario (K-fold cross-validation happens inside) 
    run_adaptive_sampling(
      initial_samples_file = result_file,
      distance_matrix = distance_matrix,
      max_iter = amc_params$max_iter,
      scenario_name = amc_scenario,
      num_samples = amc_params$num_samples,
      n_iter = amc_params$n_iter,
      batch_size = amc_params$batch_size,
      relative_epsilon = amc_params$relative_epsilon,
      folds = opt_params$folds,
      num_cores = min( opt_params$num_cores , amc_params$batch_size * opt_params$folds ), ###
      time = "18:00:00",
      memory = "30G",
      use_slurm = opt_params$use_slurm,
      cider = TRUE,
      verbose = TRUE
    )
  }
}
```

## Analyze fitted parameters Across Dimensions and Matrix Types

After all jobs complete, analyze parameter variations:

```{r}
# Initialize results collection
final_params <- data.frame()

# Collect results for each dimension and matrix type
for(ndim in results$metadata$dimension) {
  for(matrix_type in matrix_variants) {
    # Read AMC results
    amc_files <- c(
                   file.path("model_parameters",
                         sprintf("synthetic_AMC101_dim%d_%s_model_parameters.csv", 
                                ndim, matrix_type))
                   )
    # Combine chain results
    amc_results <- do.call(rbind, lapply(amc_files, read.csv))
    amc_results <- amc_results %>%
      filter(is.finite(NLL) & is.finite(Holdout_MAE)) %>%
      na.omit()
    amc_results <- amc_results[amc_results$log_N >= log(2),]
    
    amc_results <- as.data.frame(lapply(amc_results, clean_data, k = 4))
    amc_results <- na.omit(amc_results)
    
    # Find best parameters (minimum NLL)
    best_params <- amc_results[which.min(amc_results$Holdout_MAE),]
    best_params$true_dim <- ndim
    best_params$matrix_type <- matrix_type
    best_params$N <- round(exp(best_params$log_N))
    
    final_params <- rbind(final_params, best_params)
  }
}

write.csv(final_params, "optimal_parameters_250points.csv")
```


## Convergence Analysis

Check convergence for each case:

```{r}
# A helper function:
analyze_convergence <- function(ndim, matrix_type, mutual_size) {
  # Create the two specific file patterns we want to match
  file_patterns <- c(
    sprintf("synthetic_AMC101_dim%d_%s_model_parameters.csv", ndim, matrix_type)
  )

  # Get full paths for both files
  chain_files <- file.path("model_parameters", file_patterns)

  # Verify files exist
  if (!all(file.exists(chain_files))) {
    missing_files <- chain_files[!file.exists(chain_files)]
    warning("Missing chain files: ", paste(missing_files, collapse = ", "))
    chain_files <- chain_files[file.exists(chain_files)]
    if (length(chain_files) == 0) {
      stop("No chain files found for dimension ", ndim, " and matrix type ", matrix_type)
    }
  }

  # Calculate diagnostics
  diag <- calculate_diagnostics(chain_files, mutual_size = mutual_size)

  # Create diagnostic plots
  plot_file <- sprintf("synthetic_dim%d_%s_diagnostics.png", ndim, matrix_type)
  p <- create_diagnostic_plots(chain_files, mutual_size = mutual_size,
                             output_file = plot_file)

  return(list(diagnostics = diag, plot = p))
}

# Set the mutual_size, smaller then the minimum simulaations for each scenario:
mutual_size <- 20

# Analyze convergence for each case
convergence_results <- list()
for(ndim in results$metadata$dimension) {
  dim_results <- list()
  for(matrix_type in matrix_variants) {
    dim_results[[matrix_type]] <- analyze_convergence(ndim, matrix_type, mutual_size=mutual_size)
  }
}

# Print summary of convergence results
for(ndim in names(convergence_results)) {
  cat(sprintf("\nConvergence Summary for %s dimensions:\n", ndim))
  for(matrix_type in names(convergence_results[[ndim]])) {
    cat(sprintf("\nMatrix type: %s\n", matrix_type))
    print(convergence_results[[ndim]][[matrix_type]]$diagnostics)
  }
}
```


## Session Info

```{r}
sessionInfo()
```
